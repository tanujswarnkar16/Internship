{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing important libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first connect to web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\WIN-10\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data. This task will be done ips:\n",
    "\n",
    "1.first get the webpage https://www.naukri.com/\n",
    "\n",
    "2.Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "\n",
    "3.Then click the search button.\n",
    "\n",
    "4.Then scrape the data for the first 10 jobs results you get.\n",
    "\n",
    "5.Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the homepage\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter the text in search bar\n",
    "search_bar=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_bar.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter the text in Location bar\n",
    "search_loc=driver.find_element_by_id('qsb-location-sugg')\n",
    "search_loc.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on the button\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Finding tags for title\n",
    "title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "\n",
    "job_titles=[]\n",
    "for i in title_tags[:10]:\n",
    "    job_titles.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FInding tags for company name\n",
    "companies_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "companies_name=[]\n",
    "for i in companies_tags[:10]: \n",
    "    companies_name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding tags for experience required\n",
    "exp_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "\n",
    "experience_required=[]\n",
    "for i in exp_tags[:10]:\n",
    "    experience_required.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding tags for company location\n",
    "location_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")\n",
    "\n",
    "job_location=[]\n",
    "for i in location_tags[:10]:\n",
    "    job_location.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "#Printing lengths\n",
    "print(len(job_titles),len(companies_name),len(experience_required),len(job_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience_Required</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business Data Analyst(BigId) - Capco - Bangalore</td>\n",
       "      <td>Capco Technologies Pvt Ltd</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst - Flipkart Analytics</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru(Bellandur)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Pioneer Business Solutions</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sr Data Analyst</td>\n",
       "      <td>Pioneer Business Solutions</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Data Analyst - Database Design/Mining</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Urgent Openings For Data Analyst / Business An...</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Software Technologist II - Data Analyst</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hiring For Data Analyst - Payment System Intel...</td>\n",
       "      <td>Genpact</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Kwalee ltd.</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Novel Office</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0   Business Data Analyst(BigId) - Capco - Bangalore   \n",
       "1                  Data Analyst - Flipkart Analytics   \n",
       "2                                Senior Data Analyst   \n",
       "3                                    Sr Data Analyst   \n",
       "4     Business Data Analyst - Database Design/Mining   \n",
       "5  Urgent Openings For Data Analyst / Business An...   \n",
       "6            Software Technologist II - Data Analyst   \n",
       "7  Hiring For Data Analyst - Payment System Intel...   \n",
       "8                                Senior Data Analyst   \n",
       "9                                       Data Analyst   \n",
       "\n",
       "                      Company Experience_Required  \\\n",
       "0  Capco Technologies Pvt Ltd             3-8 Yrs   \n",
       "1                    Flipkart             0-3 Yrs   \n",
       "2  Pioneer Business Solutions            6-11 Yrs   \n",
       "3  Pioneer Business Solutions             3-8 Yrs   \n",
       "4                 AugmatrixGo             2-5 Yrs   \n",
       "5                    Flipkart             1-6 Yrs   \n",
       "6       Philips India Limited            6-11 Yrs   \n",
       "7                     Genpact             4-9 Yrs   \n",
       "8                 Kwalee ltd.            5-10 Yrs   \n",
       "9                Novel Office             0-3 Yrs   \n",
       "\n",
       "                                            Location  \n",
       "0                                Bangalore/Bengaluru  \n",
       "1                     Bangalore/Bengaluru(Bellandur)  \n",
       "2                                Bangalore/Bengaluru  \n",
       "3                                Bangalore/Bengaluru  \n",
       "4                                Bangalore/Bengaluru  \n",
       "5                                Bangalore/Bengaluru  \n",
       "6                                 (WFH during Covid)  \n",
       "7                                Bangalore/Bengaluru  \n",
       "8  Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...  \n",
       "9                                Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating DataFrame for the data found\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['Title']=job_titles\n",
    "jobs['Company']=companies_name\n",
    "jobs['Experience_Required']=experience_required\n",
    "jobs['Location']=job_location\n",
    "\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually.# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing important libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first connect to web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\WIN-10\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the homepage\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter the text in search bar\n",
    "search_bar=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_bar.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter the text in Location bar\n",
    "search_loc=driver.find_element_by_id('qsb-location-sugg')\n",
    "search_loc.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on the button\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Finding tags for title\n",
    "title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "\n",
    "job_titles=[]\n",
    "for i in title_tags[:10]:\n",
    "    job_titles.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##FInding tags for company name\n",
    "companies_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "companies_name=[]\n",
    "for i in companies_tags[:10]: \n",
    "    companies_name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding tags for company location\n",
    "location_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")\n",
    "\n",
    "job_location=[]\n",
    "for i in location_tags[:10]:\n",
    "    job_location.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "#Printing lengths\n",
    "print(len(job_titles),len(companies_name),len(job_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Kwalee India Pvt Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Team4Progress</td>\n",
       "      <td>Mumbai, Pune, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>TransOrg Solutions Services (P) Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist / Tech Lead - SQL / Pyth...</td>\n",
       "      <td>Exploro Solutions</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior / Lead Data Scientist</td>\n",
       "      <td>CoreEdge Solutions</td>\n",
       "      <td>Pune, Chennai, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Forecasting Analyst/ Data Scientist (US Client)</td>\n",
       "      <td>Concentrix Daksh Services</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist, Agribusiness Intelligence</td>\n",
       "      <td>IHS Markit</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kwalee India Pvt Ltd.</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Binary Fountain Solutions India Pvt. Ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                              Senior Data Scientist   \n",
       "1                                     Data Scientist   \n",
       "2                                Lead Data Scientist   \n",
       "3                                Lead Data Scientist   \n",
       "4  Senior Data Scientist / Tech Lead - SQL / Pyth...   \n",
       "5                       Senior / Lead Data Scientist   \n",
       "6    Forecasting Analyst/ Data Scientist (US Client)   \n",
       "7          Data Scientist, Agribusiness Intelligence   \n",
       "8                                     Data Scientist   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                    Company  \\\n",
       "0                     Kwalee India Pvt Ltd.   \n",
       "1                                      Visa   \n",
       "2                             Team4Progress   \n",
       "3      TransOrg Solutions Services (P) Ltd.   \n",
       "4                         Exploro Solutions   \n",
       "5                        CoreEdge Solutions   \n",
       "6                 Concentrix Daksh Services   \n",
       "7                                IHS Markit   \n",
       "8                     Kwalee India Pvt Ltd.   \n",
       "9  Binary Fountain Solutions India Pvt. Ltd   \n",
       "\n",
       "                                            Location  \n",
       "0                                Bangalore/Bengaluru  \n",
       "1                                Bangalore/Bengaluru  \n",
       "2                  Mumbai, Pune, Bangalore/Bengaluru  \n",
       "3  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...  \n",
       "4                                 (WFH during Covid)  \n",
       "5                 Pune, Chennai, Bangalore/Bengaluru  \n",
       "6  Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru  \n",
       "7              Gurgaon/Gurugram, Bangalore/Bengaluru  \n",
       "8                                 (WFH during Covid)  \n",
       "9                                Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating DataFrame for the data found\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['Title']=job_titles\n",
    "jobs['Company']=companies_name\n",
    "jobs['Location']=job_location\n",
    "\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR” The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "      1. first get the webpage https://www.naukri.com/\n",
    "      2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "      3. Then click the search button.\n",
    "      4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "      5. Then scrape the data for the first 10 jobs results you get.\n",
    "      6. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing important libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first connect to web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\WIN-10\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the homepage\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering “Data Scientist” in “Skill,Designations,Companies” field \n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "\n",
    "search_field_designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering the required details\n",
    "loc_filter=driver.find_elements_by_xpath(\"//span[@class='ellipsis fleft']\")\n",
    "for f in loc_filter:\n",
    "    if f.text=='Delhi / NCR':\n",
    "        f.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering the required details for salary\n",
    "sal_filter=driver.find_elements_by_xpath(\"//span[@class='ellipsis fleft']\")\n",
    "for i in sal_filter:\n",
    "    if i.text=='3-6 Lakhs':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Finding tags for title\n",
    "title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "\n",
    "job_titles=[]\n",
    "for i in title_tags[:10]:\n",
    "    job_titles.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Finding tags for company location\n",
    "location_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")\n",
    "\n",
    "job_location=[]\n",
    "for i in location_tags[:10]:\n",
    "    job_location.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FInding tags for company name\n",
    "companies_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "companies_name=[]\n",
    "for i in companies_tags[:10]: \n",
    "    companies_name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding tags for experience required\n",
    "exp_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "\n",
    "experience_required=[]\n",
    "for i in exp_tags[:10]:\n",
    "    experience_required.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "#printing lengths\n",
    "print(len(job_titles),len(companies_name),len(experience_required),len(job_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience_Required</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Think i</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>Kochi/Cochin, Kolkata, Hyderabad/Secunderabad,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>ThinkBumblebee Analytics Pvt. Ltd.</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>Pune, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist III-2</td>\n",
       "      <td>Concentrix Daksh Services</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Job Opportunity || Data Scientist || HCL Techn...</td>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>MoMagic Technologies Pvt. Ltd.</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>MoMagic Technologies Pvt. Ltd.</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "      <td>Noida(Sector-126 Noida)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Urgent Hiring || Data Scientist || Delhi</td>\n",
       "      <td>Shriram Automall India Limited</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Noida(Sector-126 Noida)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>SVK Global Solutions Private Limited</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist Internship</td>\n",
       "      <td>iHackers Inc</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                                     Data Scientist   \n",
       "1                                     Data Scientist   \n",
       "2                               Data Scientist III-2   \n",
       "3  Job Opportunity || Data Scientist || HCL Techn...   \n",
       "4                                     Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6           Urgent Hiring || Data Scientist || Delhi   \n",
       "7                                     Data Scientist   \n",
       "8                          Data Scientist Internship   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                          Company Experience_Required  \\\n",
       "0                                         Think i             0-2 Yrs   \n",
       "1              ThinkBumblebee Analytics Pvt. Ltd.             2-6 Yrs   \n",
       "2                       Concentrix Daksh Services             3-8 Yrs   \n",
       "3                                HCL Technologies             4-7 Yrs   \n",
       "4                  MoMagic Technologies Pvt. Ltd.             4-6 Yrs   \n",
       "5                  MoMagic Technologies Pvt. Ltd.             4-6 Yrs   \n",
       "6                  Shriram Automall India Limited             2-7 Yrs   \n",
       "7            SVK Global Solutions Private Limited            6-10 Yrs   \n",
       "8                                    iHackers Inc             0-1 Yrs   \n",
       "9  Optum Global Solutions (India) Private Limited             2-6 Yrs   \n",
       "\n",
       "                                            Location  \n",
       "0  Kochi/Cochin, Kolkata, Hyderabad/Secunderabad,...  \n",
       "1             Pune, Bangalore/Bengaluru, Delhi / NCR  \n",
       "2                                 (WFH during Covid)  \n",
       "3                                   Gurgaon/Gurugram  \n",
       "4                                        Delhi / NCR  \n",
       "5                            Noida(Sector-126 Noida)  \n",
       "6                            Noida(Sector-126 Noida)  \n",
       "7                                        Delhi / NCR  \n",
       "8                                              Noida  \n",
       "9                                          New Delhi  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating DataFrame for the data found\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['Title']=job_titles\n",
    "jobs['Company']=companies_name\n",
    "jobs['Experience_Required']=experience_required\n",
    "jobs['Location']=job_location\n",
    "\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the\n",
    "required data as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing important libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first connect to web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\WIN-10\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the homepage\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#providing the required details\n",
    "search_prod = driver.find_element_by_name('q')\n",
    "search_prod.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking the search button\n",
    "search_button = driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty list to store value and printing brand name on page 1\n",
    "brand = []\n",
    "brand = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "brand_name = []\n",
    "for i in brand:\n",
    "    brand_name.append(i.text)\n",
    "\n",
    "len(brand_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty list to store value and printing description of product on page 1\n",
    "desc = []\n",
    "desc = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "\n",
    "des = []\n",
    "for i in desc:\n",
    "    des.append(i.text)\n",
    "    \n",
    "len(des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty list to store value and printing price of products on page 1\n",
    "pric = []\n",
    "pric = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "\n",
    "price = []\n",
    "for i in pric:\n",
    "    price.append(i.text)\n",
    "    \n",
    "len(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty list to store value and printing discount of products on page 1\n",
    "dis = []\n",
    "dis = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\")\n",
    "\n",
    "disc = []\n",
    "for i in dis:\n",
    "    disc.append(i.text)\n",
    "    \n",
    "len(disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xpath to get on page 2\n",
    "next_button = driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty list to store value and printing brand name on page 2\n",
    "brand2 = []\n",
    "brand2 = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "\n",
    "for i in brand2:\n",
    "    brand_name.append(i.text)\n",
    "    \n",
    "len(brand_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty list to store value and printing description of product on page 2\n",
    "desc2 = []\n",
    "desc2 = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "for i in desc2:\n",
    "    des.append(i.text)\n",
    "    \n",
    "len(des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##creating empty list to store value and printing price of products on page 2\n",
    "pric2 = []\n",
    "pric2 = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "\n",
    "for i in pric2:\n",
    "    price.append(i.text)\n",
    "    \n",
    "len(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty list to store value and printing discount of products on page 2\n",
    "dis2 = []\n",
    "dis2 = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\")\n",
    "\n",
    "for i in dis2:\n",
    "    disc.append(i.text)\n",
    "    \n",
    "len(disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to get on page 3\n",
    "target_url = []\n",
    "url = driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "for i in url:\n",
    "    target_url.append(i.get_attribute('href'))\n",
    "    \n",
    "driver.get(target_url[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty list to store value and printing brand name on page 3\n",
    "brand3 = []\n",
    "brand3 = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "\n",
    "for i in brand3:\n",
    "    brand_name.append(i.text)\n",
    "    \n",
    "len(brand_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty list to store value and printing description of product on page 3\n",
    "desc3 = []\n",
    "desc3 = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "for i in desc3:\n",
    "    des.append(i.text)\n",
    "\n",
    "len(des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty list to store value and printing price of products on page 3\n",
    "pric3 = []\n",
    "pric3 = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "for i in pric3:\n",
    "    price.append(i.text)\n",
    "    \n",
    "len(price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty list to store value and printing discount of products on page 3\n",
    "dis3 = []\n",
    "dis3 = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\")\n",
    "for i in dis3:\n",
    "    disc.append(i.text)\n",
    "    \n",
    "len(disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120 120\n"
     ]
    }
   ],
   "source": [
    "#printing length\n",
    "print(len(brand_name),len(disc),len(price),len(des))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting data from 0 to 100\n",
    "brand_name = brand_name[0:100]\n",
    "price= price[0:100]\n",
    "disc = disc[0:100]\n",
    "des = des[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating DataFrame from above lists\n",
    "product_info = pd.DataFrame({})\n",
    "product_info['Brand'] = brand_name\n",
    "product_info['Price'] = price\n",
    "product_info['Discounts'] = disc\n",
    "product_info['Description'] = des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discounts</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>₹248</td>\n",
       "      <td>90% off</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>₹188</td>\n",
       "      <td>85% off</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (56)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>₹276</td>\n",
       "      <td>83% off</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Round Sungl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹200</td>\n",
       "      <td>87% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹513</td>\n",
       "      <td>35% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>₹330</td>\n",
       "      <td>73% off</td>\n",
       "      <td>UV Protection Sports Sunglasses (73)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>₹345</td>\n",
       "      <td>62% off</td>\n",
       "      <td>UV Protection, Mirrored, Night Vision, Riding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Poland</td>\n",
       "      <td>₹165</td>\n",
       "      <td>66% off</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>₹205</td>\n",
       "      <td>84% off</td>\n",
       "      <td>UV Protection, Mirrored Round Sunglasses (Free...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>hipe</td>\n",
       "      <td>₹233</td>\n",
       "      <td>76% off</td>\n",
       "      <td>UV Protection, Gradient, Riding Glasses Wayfar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Brand Price Discounts  \\\n",
       "0    Elligator  ₹248   90% off   \n",
       "1         SRPM  ₹188   85% off   \n",
       "2       SUNBEE  ₹276   83% off   \n",
       "3       PIRASO  ₹200   87% off   \n",
       "4     Fastrack  ₹513   35% off   \n",
       "..         ...   ...       ...   \n",
       "95       NuVew  ₹330   73% off   \n",
       "96       NuVew  ₹345   62% off   \n",
       "97      Poland  ₹165   66% off   \n",
       "98  PHENOMENAL  ₹205   84% off   \n",
       "99        hipe  ₹233   76% off   \n",
       "\n",
       "                                          Description  \n",
       "0                 UV Protection Round Sunglasses (54)  \n",
       "1              UV Protection Wayfarer Sunglasses (56)  \n",
       "2   UV Protection, Polarized, Mirrored Round Sungl...  \n",
       "3               UV Protection Aviator Sunglasses (54)  \n",
       "4    UV Protection Rectangular Sunglasses (Free Size)  \n",
       "..                                                ...  \n",
       "95               UV Protection Sports Sunglasses (73)  \n",
       "96  UV Protection, Mirrored, Night Vision, Riding ...  \n",
       "97      UV Protection Wayfarer Sunglasses (Free Size)  \n",
       "98  UV Protection, Mirrored Round Sunglasses (Free...  \n",
       "99  UV Protection, Gradient, Riding Glasses Wayfar...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#result\n",
    "product_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to go the link:\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-poweradapter/\n",
    "p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\n",
    "TSVZAXUHGREPBFGI&marketplace.\n",
    "When you will open the above link you will reach to the below shown webpage ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews.\n",
    "Note: All the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "##importing important libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first connect to web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\WIN-10\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the homepage\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includesearpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking the search button\n",
    "searchbtn=driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']/span\")\n",
    "searchbtn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rating  Short Description  \\\n",
      "0       5          Brilliant   \n",
      "1       5     Simply awesome   \n",
      "2       5   Perfect product!   \n",
      "3       5  Worth every penny   \n",
      "4       5          Fabulous!   \n",
      "..    ...                ...   \n",
      "95      5             Super!   \n",
      "96      5          Just wow!   \n",
      "97      5  Terrific purchase   \n",
      "98      5            Awesome   \n",
      "99      3     Decent product   \n",
      "\n",
      "                                          Full review  \n",
      "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
      "1   Really satisfied with the Product I received.....  \n",
      "2   Amazing phone with great cameras and better ba...  \n",
      "3   Previously I was using one plus 3t it was a gr...  \n",
      "4   This is my first iOS phone. I am very happy wi...  \n",
      "..                                                ...  \n",
      "95  This is my first ever iPhone.\\nAnd I truly don...  \n",
      "96  The ultimate performance\\nCamera is superb\\nTh...  \n",
      "97  I use a Note10+ and have been using both iOS a...  \n",
      "98  The phone is completely good\\nAs far as camera...  \n",
      "99  Everything u ll like it when u use this iPhone...  \n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating empty list to store data\n",
    "ratings = []\n",
    "review_summ = []\n",
    "full_reviews = []\n",
    "\n",
    "# looping through 10 pages to get 100 reiews(10reviews/page)\n",
    "for i in range (0, 11):\n",
    "    #getting the information div by class\n",
    "    divs = driver.find_elements_by_class_name(\"_2wzgFH\")\n",
    "    for div in divs:\n",
    "        #appending info to the lists\n",
    "        ratings.append(div.find_element_by_class_name('_3LWZlK').text)\n",
    "        review_summ.append(div.find_element_by_class_name('_2-N8zT').text)\n",
    "        full_reviews.append(div.find_element_by_class_name('t-ZTKy').text)\n",
    "    next_page = driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "    try:\n",
    "        #go to next page\n",
    "        driver.get(next_page[1].get_attribute('href'))\n",
    "    except:\n",
    "        driver.get(next_page[0].get_attribute('href'))\n",
    "#creatinf dataframe\n",
    "reviews = pd.DataFrame({'Rating':ratings[:100],\n",
    "                'Short Description':review_summ[:100],\n",
    "                'Full review':full_reviews[:100]})\n",
    "print(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the tick marked attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: All the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "###importing important libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first connect to web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\WIN-10\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the homepage\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the element and sending keys for search as required\n",
    "search_prod = driver.find_element_by_name('q')\n",
    "search_prod.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on search button\n",
    "search_button = driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list and storing brand name, description and price of page 1\n",
    "Brand_name1=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "Brand_name1\n",
    "Brand_name2=[]\n",
    "for i in Brand_name1:\n",
    "    Brand_name2.append(i.text)\n",
    "\n",
    "\n",
    "Product_des1=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "Product_des1\n",
    "Product_des2=[]\n",
    "for i in Product_des1:\n",
    "    Product_des2.append(i.text)\n",
    "    \n",
    "\n",
    "Price1=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "Price1\n",
    "Price2=[]\n",
    "for i in Price1:\n",
    "    Price2.append(i.text)\n",
    "    \n",
    "Discount=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "Discount2=[]\n",
    "for i in Discount:\n",
    "    Discount2.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing the code to get on page 2\n",
    "second_page=driver.find_element_by_xpath('//nav/a[@class=\"_1LKTO3\" ]/span[text() = \"Next\"]')\n",
    "second_page1=second_page.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating empty list and storing brand name, description and price of page 2\n",
    "Brand_name3=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "Brand_name3\n",
    "Brand_name4=[]\n",
    "for i in Brand_name3:\n",
    "    Brand_name4.append(i.text)\n",
    "Brand_name4\n",
    "\n",
    "Product_des3=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "Product_des4=[]\n",
    "for i in Product_des3:\n",
    "    Product_des4.append(i.text)\n",
    "\n",
    "Price3=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "Price4=[]\n",
    "for i in Price3:\n",
    "    Price4.append(i.text)\n",
    "\n",
    "Discount3=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "Discount4=[]\n",
    "for i in Discount3:\n",
    "    Discount4.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "##parsing the code to get on page 3\n",
    "second_page=driver.find_element_by_xpath('//nav/a[@class=\"_1LKTO3\" ]/span[text() = \"Next\"]')\n",
    "second_page1=second_page.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating empty list and storing brand name, description and price of page 3\n",
    "Brand_name5=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "Brand_name6=[]\n",
    "for i in Brand_name5:\n",
    "    Brand_name6.append(i.text)\n",
    "\n",
    "\n",
    "Product_des5=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "Product_des6=[]\n",
    "for i in Product_des5:\n",
    "    Product_des6.append(i.text)\n",
    "\n",
    "\n",
    "Price5=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "Price6=[]\n",
    "for i in Price5:\n",
    "    Price6.append(i.text)\n",
    "\n",
    "\n",
    "Discount5=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "Discount6=[]\n",
    "for i in Discount5:\n",
    "    Discount6.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appending all the data into single list of brand name, description, price and discount\n",
    "Brand_name=Brand_name2+Brand_name4+Brand_name6\n",
    "Product_des=Product_des2+Product_des4+Product_des6\n",
    "Price=Price2+Price4+Price6\n",
    "Discount=Discount2+Discount4+Discount6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating DataFrame\n",
    "Sneakers=pd.DataFrame({})\n",
    "Sneakers[\"Brand_name\"]=Brand_name[0:80]\n",
    "Sneakers[\"Product_Description\"]=Product_des[0:80]\n",
    "Sneakers[\"Price\"]=Price[0:80]\n",
    "Sneakers[\"Discount\"]=Discount[0:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand_name</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Sports Shoes Sneakers For Men</td>\n",
       "      <td>₹299</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOTSTYLE</td>\n",
       "      <td>White Boots || High Tops || Sneakers For Men</td>\n",
       "      <td>₹654</td>\n",
       "      <td>34% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOOTGRAB</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹549</td>\n",
       "      <td>45% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹479</td>\n",
       "      <td>63% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kreverse</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹245</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>PLOTA</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Trendy Casual Shoes Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>HOC</td>\n",
       "      <td>RS-Z BP Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Puma Wired Cage Sneakers For Men</td>\n",
       "      <td>₹474</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>PLOTA</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Brand_name                           Product_Description Price Discount\n",
       "0          BIRDE                 Sports Shoes Sneakers For Men  ₹299  70% off\n",
       "1       HOTSTYLE  White Boots || High Tops || Sneakers For Men  ₹654  34% off\n",
       "2       FOOTGRAB                              Sneakers For Men  ₹549  45% off\n",
       "3        Numenzo                              Sneakers For Men  ₹479  63% off\n",
       "4       Kreverse                              Sneakers For Men  ₹245  75% off\n",
       "..           ...                                           ...   ...      ...\n",
       "75         PLOTA                              Sneakers For Men  ₹499  50% off\n",
       "76  Robbie jones          Trendy Casual Shoes Sneakers For Men  ₹499  77% off\n",
       "77           HOC                      RS-Z BP Sneakers For Men  ₹449  81% off\n",
       "78        BRUTON              Puma Wired Cage Sneakers For Men  ₹474  50% off\n",
       "79         PLOTA                              Sneakers For Men  ₹499  76% off\n",
       "\n",
       "[80 rows x 4 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#result\n",
    "Sneakers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "due to some product are out of stock no data is available thats why i have taken data upto 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7: Go to the link - https://www.myntra.com/shoes. Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in the below image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe\n",
    "description, price of the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Applying the filter and scraping the data, everything should be done through code only and there\n",
    "should not be any manual step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "###importing important libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first connect to web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\WIN-10\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the homepage\n",
    "driver.get(\"https://www.myntra.com/shoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Casual Shoes(20898)',\n",
       " 'Flats(16652)',\n",
       " 'Heels(15830)',\n",
       " 'Sports Shoes(9379)',\n",
       " 'Formal Shoes(6608)',\n",
       " 'Booties(197)',\n",
       " 'Rs. 199 to Rs. 7149(67220)',\n",
       " 'Rs. 7149 to Rs. 14099(2172)',\n",
       " 'Rs. 14099 to Rs. 21049(163)',\n",
       " 'Rs. 21049 to Rs. 27999(7)']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding by xpath and clicking on price range list\n",
    "search_range = driver.find_elements_by_xpath(\"//label[@class='common-customCheckbox vertical-filters-label']\")\n",
    "\n",
    "click=[]\n",
    "for i in search_range:\n",
    "    click.append(i.text)\n",
    "\n",
    "click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting price range\n",
    "for i in search_range:\n",
    "    if i.text == 'Rs. 7149 to Rs. 14099(2120)':\n",
    "        i.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Black (17520)',\n",
       " 'Brown (5656)',\n",
       " 'White (4906)',\n",
       " 'Grey (4707)',\n",
       " 'Navy Blue (4547)',\n",
       " 'Tan (4105)',\n",
       " 'Blue (3961)']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding and selecting the colour list\n",
    "colors = []\n",
    "color = driver.find_elements_by_xpath(\"//label[@class='common-customCheckbox']\")\n",
    "\n",
    "for i in color:\n",
    "    colors.append(i.text)\n",
    "\n",
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting the required colour as asked\n",
    "for i in color:\n",
    "    if i.text == 'Black (718)':\n",
    "        i.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to store data\n",
    "brand = [] \n",
    "descr = [] \n",
    "price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting brand name, description and price of products on page 1\n",
    "brand_name = driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "for i in brand_name:\n",
    "    brand.append(i.text)\n",
    "    \n",
    "short_desc = driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "for i in short_desc:\n",
    "    descr.append(i.text)\n",
    "    \n",
    "value = driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "for i in value:\n",
    "    price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing the code to get on page 2\n",
    "next_page = driver.find_element_by_xpath(\"//li[@class='pagination-next']\")\n",
    "next_page.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting brand name, description and price of products on page 1\n",
    "brand_name2 = driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "for i in brand_name2:\n",
    "    brand.append(i.text)\n",
    "    \n",
    "short_desc2 = driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "for i in short_desc2:\n",
    "    descr.append(i.text)\n",
    "    \n",
    "value2 = driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "for i in value2:\n",
    "    price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing all the values into DataFrame\n",
    "shoes_descr = pd.DataFrame({})\n",
    "shoes_descr[\"Brand\"] = brand\n",
    "shoes_descr[\"Price\"] = price\n",
    "shoes_descr[\"Description\"] = descr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H&amp;M</td>\n",
       "      <td>Rs. 2699</td>\n",
       "      <td>Chunky Combat Boots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HIGHLANDER</td>\n",
       "      <td>Rs. 1990</td>\n",
       "      <td>Men Solid Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Newfeel By Decathlon</td>\n",
       "      <td>Rs. 899</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Rs. 2009Rs. 2999(33% OFF)</td>\n",
       "      <td>Men Woven Design Running Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TWIN TOES</td>\n",
       "      <td>Rs. 799Rs. 999(Rs. 200 OFF)</td>\n",
       "      <td>Women Colourblocked Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Rs. 5999</td>\n",
       "      <td>Men ELITE FLEX Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Mochi</td>\n",
       "      <td>Rs. 3990</td>\n",
       "      <td>Men Textured Leather Oxfords</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Mactree</td>\n",
       "      <td>Rs. 664Rs. 3321(80% OFF)</td>\n",
       "      <td>Men Solid Formal Derbys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Rs. 4499Rs. 4999(10% OFF)</td>\n",
       "      <td>Men Textured Formal Derbys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>U.S. Polo Assn.</td>\n",
       "      <td>Rs. 2519Rs. 3599(30% OFF)</td>\n",
       "      <td>Men Solid Loafers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Brand                        Price  \\\n",
       "0                    H&M                     Rs. 2699   \n",
       "1             HIGHLANDER                     Rs. 1990   \n",
       "2   Newfeel By Decathlon                      Rs. 899   \n",
       "3                 ADIDAS    Rs. 2009Rs. 2999(33% OFF)   \n",
       "4              TWIN TOES  Rs. 799Rs. 999(Rs. 200 OFF)   \n",
       "..                   ...                          ...   \n",
       "95              Skechers                     Rs. 5999   \n",
       "96                 Mochi                     Rs. 3990   \n",
       "97               Mactree     Rs. 664Rs. 3321(80% OFF)   \n",
       "98          Hush Puppies    Rs. 4499Rs. 4999(10% OFF)   \n",
       "99       U.S. Polo Assn.    Rs. 2519Rs. 3599(30% OFF)   \n",
       "\n",
       "                       Description  \n",
       "0              Chunky Combat Boots  \n",
       "1               Men Solid Sneakers  \n",
       "2                Men Walking Shoes  \n",
       "3   Men Woven Design Running Shoes  \n",
       "4     Women Colourblocked Sneakers  \n",
       "..                             ...  \n",
       "95         Men ELITE FLEX Sneakers  \n",
       "96    Men Textured Leather Oxfords  \n",
       "97         Men Solid Formal Derbys  \n",
       "98      Men Textured Formal Derbys  \n",
       "99               Men Solid Loafers  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#result\n",
    "shoes_descr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price\n",
    "\n",
    "As shown in the below image as the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing important libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first connect to web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\WIN-10\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the homepage\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching and filling the web element as required\n",
    "search_lap = driver.find_element_by_id('twotabsearchtextbox')\n",
    "search_lap.send_keys(\"laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing the code to click on search button\n",
    "search_button = driver.find_element_by_id('nav-search-submit-button')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing the code to select i7 category\n",
    "search_i7 = driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']\")\n",
    "for i in search_i7:\n",
    "    if i.text == 'Intel Core i7':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing the code to select i9 category\n",
    "search_i9 = driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']\")\n",
    "for i in search_i9:\n",
    "    if i.text == 'Intel Core i9':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to store data\n",
    "title=[]\n",
    "rating=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the web element and getting title data\n",
    "t=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "t[0:10]\n",
    "for i in t:\n",
    "    ti=i.text\n",
    "    title.append(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the web element and getting rating of products data\n",
    "ra=driver.find_elements_by_xpath(\"//span[@class='a-size-base']\")\n",
    "ra[0:10]\n",
    "for i in ra:\n",
    "    tar=i.text\n",
    "    rating.append(tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the web element and getting product price data\n",
    "p=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "p[0:10]\n",
    "for i in p:\n",
    "    pr=i.text\n",
    "    price.append(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LG Gram 17 Ultra-Light Intel Evo 11th Gen Core...</td>\n",
       "      <td>33</td>\n",
       "      <td>1,06,057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LG Gram 14 Ultralight Intel Evo 11th Gen Core ...</td>\n",
       "      <td>43</td>\n",
       "      <td>87,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP Pavilion (2021) Intel 11th Gen Core i7 14 i...</td>\n",
       "      <td>537</td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>895</td>\n",
       "      <td>59,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acer Nitro 5 11th Gen Intel Core i7-11800H 15....</td>\n",
       "      <td>51</td>\n",
       "      <td>85,911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo Yoga 7i 11th Gen Intel Core i7-1165G7 1...</td>\n",
       "      <td>60</td>\n",
       "      <td>1,09,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS TUF Gaming F17 (2021), 17.3-inch (43.94 c...</td>\n",
       "      <td>6</td>\n",
       "      <td>1,13,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14-inc...</td>\n",
       "      <td>427</td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dell 14 (2021) i7-1195G7 2in1 Touch Screen Lap...</td>\n",
       "      <td>1</td>\n",
       "      <td>88,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS TUF Dash F15 (2021) 15.6-inch (39.62 cms)...</td>\n",
       "      <td>15</td>\n",
       "      <td>93,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title rating     price\n",
       "0  LG Gram 17 Ultra-Light Intel Evo 11th Gen Core...     33  1,06,057\n",
       "1  LG Gram 14 Ultralight Intel Evo 11th Gen Core ...     43    87,999\n",
       "2  HP Pavilion (2021) Intel 11th Gen Core i7 14 i...    537    84,990\n",
       "3  Mi Notebook Horizon Edition 14 Intel Core i7-1...    895    59,990\n",
       "4  Acer Nitro 5 11th Gen Intel Core i7-11800H 15....     51    85,911\n",
       "5  Lenovo Yoga 7i 11th Gen Intel Core i7-1165G7 1...     60  1,09,990\n",
       "6  ASUS TUF Gaming F17 (2021), 17.3-inch (43.94 c...      6  1,13,990\n",
       "7  HP Pavilion x360 11th Gen Intel Core i7 14-inc...    427    84,990\n",
       "8  Dell 14 (2021) i7-1195G7 2in1 Touch Screen Lap...      1    88,490\n",
       "9  ASUS TUF Dash F15 (2021) 15.6-inch (39.62 cms)...     15    93,990"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataFrame and storing values and printing result\n",
    "laptop=pd.DataFrame({})\n",
    "laptop['title']=title[0:10]\n",
    "laptop['rating']=rating[0:10]\n",
    "laptop['price']=price[0:10]\n",
    "laptop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location. You have to scrape company name, No. of days ago when job was posted, Rating of the company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the Job option as shown in the image\n",
    "3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter\n",
    "“Data Scientist” and click on search button.\n",
    "4. You will reach to the following web page click on location and in place of “Search location” enter\n",
    "“Noida” and select location “Noida”.\n",
    "5. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "6. Finally create a dataframe of the scraped data.\n",
    "\n",
    "Note: All the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing important libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first connect to web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\WIN-10\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the homepage\n",
    "driver.get(\"https://www.ambitionbox.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the element and click on 'Jobs' \n",
    "l=driver.find_element_by_xpath(\"//a[@title='Jobs']\")\n",
    "l.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding web element and search as required\n",
    "search_lap = driver.find_element_by_name('ab_jobsSearch')\n",
    "search_lap.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on the button\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='ab_btn search-btn round']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image.\n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and\n",
    "then click on “Data Scientist”.\n",
    "You have to scrape the data ticked in the above image.\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average\n",
    "salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe.\n",
    "Note: All the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing important libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first connect to web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\WIN-10\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the homepage\n",
    "driver.get(\" https://www.ambitionbox.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the element and click on 'Company Salaries' \n",
    "l=driver.find_element_by_xpath(\"//a[@title='Company Salaries']\")\n",
    "l.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding web element and search as required\n",
    "search_lap = driver.find_element_by_name('CompanyName')\n",
    "search_lap.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter the text in search bar\n",
    "search_bar=driver.find_element_by_id('jobProfileSearchbox')\n",
    "search_bar.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
